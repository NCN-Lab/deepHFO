# -*- coding: utf-8 -*-
"""predict markers from original signal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I1mn0DRkeestFbi6aQ0c-nd8RHnZ11Dt

#Imports
"""
import numpy as np
from scipy.signal import butter, lfilter
import time
import os

from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam

import tensorflow as tf


"""PRE PROCESSING"""
#Filter functions
def butter_bandpass(lowcut, highcut, fs, order=5):
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low, high], btype='band')
    return b, a


def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):
    b, a = butter_bandpass(lowcut, highcut, fs, order=order)
    y = lfilter(b, a, data)
    return y

def filter_ripples(data, channels, sr, update_progress_method, start_prog, prog_advance):
  lowcut = 80.0
  highcut = 250.0
  order = 9

  filtered_data=np.zeros(np.shape(data))
  for c in range(len(channels)):
    filtered_data[c,:]=butter_bandpass_filter(data[c,:], lowcut, highcut, sr, order=order)
    perc=start_prog+c/len(channels)*prog_advance
    update_progress_method(perc)

  return filtered_data

def filter_fast_ripples(data, channels, sr, update_progress_method, start_prog, prog_advance):
  lowcut = 250
  highcut = 500.0
  order = 9

  filtered_data=np.zeros(np.shape(data))
  for c in range(len(channels)):
    filtered_data[c,:]=butter_bandpass_filter(data[c,:], lowcut, highcut, sr, order=order)
    perc=start_prog+c/len(channels)*prog_advance
    update_progress_method(perc)

  return filtered_data

#Windowing functions

def window_data(filtered_data, size_window, update_progress_method, start_prog, prog_advance):
  n_channels=len(filtered_data[:,0])
  samples=len(filtered_data[0,:])
  n_windows=int(2*(samples/size_window)-1)
  X=np.zeros((n_channels,n_windows,size_window))
  for i in range(n_channels):
    for j in range(n_windows):
      beg=int(j*size_window/2)
      end=min(beg+size_window,samples)
      X[i,j,:]=(filtered_data[i,beg:end]-np.mean(filtered_data[i,beg:end]))/np.std(filtered_data[i,beg:end])
    perc=start_prog+i/n_channels*prog_advance
    update_progress_method(perc)
  return X

#pre processing function
def pre_processing(data,channels,sr, update_progress_method):
   
    size_window=256
    
    data_r=filter_ripples(data,channels, sr, update_progress_method,0,10)
    data_fr=filter_fast_ripples(data,channels, sr, update_progress_method,10,10)
    
    Xr=window_data(data_r, size_window, update_progress_method,20,40)
    Xfr=window_data(data_fr, size_window, update_progress_method,60,40)
    
    return Xr, Xfr




"""PREDICTION"""

#Inference
def models_predictions(Xr, Xfr, n_channels, n_windows, update_progress_method):
    lr=0.001
    b1=0.9
    b2=0.999
    ep=1e-7
    bs=1024
      
    m_dir=os.path.join(os.path.dirname(os.path.abspath(__file__)),"models")
    print(m_dir)
    m_file_r="model ripples.h5"
    m_file_fr="model fast ripples.h5"
      
    optimizer = Adam(learning_rate=lr, beta_1=b1, beta_2=b2, epsilon=ep, amsgrad=False)
    model = load_model(os.path.join(m_dir,m_file_r), compile=False)
    model.compile(loss="binary_crossentropy", optimizer=optimizer)
    
    preds_r=np.zeros((n_channels,n_windows,1))
    for c in range(n_channels):
      preds_r[c,:] = model.predict(Xr[c], batch_size=bs, verbose=True)
      update_progress_method(c/n_channels*50)


    model = load_model(os.path.join(m_dir,m_file_fr), compile=False)
    model.compile(loss="binary_crossentropy", optimizer=optimizer)

    preds_fr=np.zeros((n_channels,n_windows,1))
    for c in range(n_channels):
      preds_fr[c,:] = model.predict(Xfr[c], batch_size=bs, verbose=True)
      update_progress_method(49+c/n_channels*50)
      
    preds=np.zeros((n_channels,n_windows,2))
    preds[:,:,0]=preds_r[:,:,0]
    preds[:,:,1]=preds_fr[:,:,0]

    return preds

#Binarization
def binary_models_preds(preds, n_channels, n_windows):

  preds_bin=np.zeros(np.shape(preds))

  for c in range(n_channels):
    n=0
    while n<n_windows-1:
      if preds[c,n,0]>0.3:
        i=n
        while preds[c,n,0]>0.3:
          f=n
          n=n+1
          if n==n_windows:
            break
        if np.max(preds[c,i:f+1,0])>0.5:
          preds_bin[c,i:f+1,0]=np.ones(f-i+1)
      n=n+1

  for c in range(n_channels):
    n=0
    while n<n_windows-1:
      if preds[c,n,1]>0.3:
        i=n
        while preds[c,n,1]>0.3:
          f=n
          n=n+1
          if n==n_windows:
            break
        if np.max(preds[c,i:f+1,1])>0.5:
          preds_bin[c,i:f+1,1]=np.ones(f-i+1)
      n=n+1

  return preds_bin

#HFO events
def hfo_preds(preds_bin, n_channels, n_windows, size_window):

  PREDr=[[] for c in range(n_channels)]
  for c in range(n_channels):
    n=0
    while n<n_windows-1:
      if preds_bin[c,n,0]==1:
        i=n
        while preds_bin[c,n,0]==1:
          f=n
          n=n+1
          if n==n_windows:
            break
        PREDr[c].append([i,f])
      n=n+1

  PREDfr=[[] for c in range(n_channels)]
  for c in range(n_channels):
    n=0
    while n<n_windows-1:
      if preds_bin[c,n,1]==1:
        i=n
        while preds_bin[c,n,1]==1:
          f=n
          n=n+1
          if n==n_windows:
            break
        PREDfr[c].append([i,f])
      n=n+1
  return PREDr, PREDfr

# Prediction
def predict_hfo(Xr, Xfr, update_progress_method):
  n_channels=len(Xr[:,0,0])
  n_windows=len(Xr[0,:,0])
  size_window=len(Xr[0,0,:])

  preds=models_predictions(Xr, Xfr, n_channels, n_windows, update_progress_method)

  preds_bin=binary_models_preds(preds, n_channels, n_windows)
  update_progress_method(99)
  PREDr,PREDfr=hfo_preds(preds_bin, n_channels, n_windows, size_window)
  update_progress_method(100)

  return PREDr, PREDfr


"""POST PROCESSING"""

#frequency estimation
def fft(signal, fs, N):
  nyq=fs/2
  y=signal-np.mean(signal)
  f=np.fft.fft(y)
  L=int(len(f)/2)
  f=abs(f[:L])/L
  freqs=np.linspace(0,nyq,L)

  f=np.convolve(np.reshape(f,(-1)),np.ones((N))/N, 'same')

  return f, freqs

def freq_estimation(X, PRED, fs, size_window):
  i=PRED[0]
  e=PRED[1]

  if i==e:
    signal=X[i]
  else:
    signal=np.append(X[i],X[i+1][int(size_window/2):])
    for p in range(i+2,e+1):
      signal=np.append(signal,X[p][int(size_window/2):])
  t = np.arange(len(signal)) / fs

  N=7
  f,freqs=fft(signal, fs,N)

  peak=np.max(abs(f)**2)
  oscillation_frequency=np.mean(freqs[abs(f)**2>0.99*peak])

  return oscillation_frequency

#post processing
def post_processing(Xr, Xfr, PREDr, PREDfr, sr, update_progress_method):
  n_channels=len(Xr[:,0,0])
  n_windows=len(Xr[0,:,0])
  size_window=len(Xr[0,0,:])

  markers=[[] for c in range(n_channels)]
  for c in range(n_channels):
    for pred in PREDr[c]:

      pi=pred[0]*(size_window/2)
      pf=(pred[1]+2)*(size_window/2)

      t=((pi+pf)/2)/sr
      dur=(pf-pi)/sr
      freq=freq_estimation(Xr[c,:,:],pred,sr, size_window)

      markers[c].append(('R',t,dur,freq))

    for pred in PREDfr[c]:

      pi=pred[0]*(size_window/2)
      pf=(pred[1]+2)*(size_window/2)

      t=((pi+pf)/2)/sr
      dur=(pf-pi)/sr
      freq=freq_estimation(Xfr[c,:,:],pred,sr, size_window)

      markers[c].append(('FR',t,dur,freq))
    
    update_progress_method((c+1)/n_channels*100)

  return markers

